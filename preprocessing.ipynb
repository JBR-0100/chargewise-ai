{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fda5ba53",
   "metadata": {},
   "source": [
    "# Milestone 1 — EV Charging Demand Prediction\n",
    "\n",
    "## 1. Problem Understanding\n",
    "\n",
    "**Objective:** Build a machine-learning / time-series forecasting system that predicts EV charging demand at stations using historical usage data from the **UrbanEVDataset** (Shenzhen, China — Sep 2022 to Feb 2023).\n",
    "\n",
    "### Use-Case Description\n",
    "EV charging stations in urban areas experience highly variable demand patterns driven by:\n",
    "- **Time of day** (rush hours vs. off-peak)\n",
    "- **Day of week** (weekdays vs. weekends)\n",
    "- **Season** (weather, holidays)\n",
    "- **Station location** (residential area vs. commercial)\n",
    "\n",
    "Accurate demand forecasting enables:\n",
    "- Grid operators to balance electricity load\n",
    "- Station managers to schedule maintenance\n",
    "- EV drivers to find available chargers\n",
    "\n",
    "### Input–Output Specification\n",
    "| Field | Description |\n",
    "|---|---|\n",
    "| **Inputs** | Historical 5-min interval station data (busy/idle piles, energy volume, price, duration) |\n",
    "| **Station Info** | GPS coordinates, pile counts, zone (TAZID) |\n",
    "| **Outputs** | Hourly energy demand forecast (kWh) per zone |\n",
    "| **Evaluation** | MAE, RMSE on held-out 20% test split |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e492c55",
   "metadata": {},
   "source": [
    "## 2. Forecasting Pipeline (System Architecture)\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│                     FORECASTING PIPELINE                           │\n",
    "│                                                                     │\n",
    "│  Raw Station CSVs (5-min)                                           │\n",
    "│       │                                                             │\n",
    "│       ▼                                                             │\n",
    "│  Data Cleaning & Gap-Filling (ffill/bfill)                          │\n",
    "│       │                                                             │\n",
    "│       ▼                                                             │\n",
    "│  Remove Bad Stations (all-idle / header-only)                       │\n",
    "│       │                                                             │\n",
    "│       ▼                                                             │\n",
    "│  Hourly Aggregation (per-station → sum/mean)                        │\n",
    "│       │                                                             │\n",
    "│  Station Info CSV ──► Zone Mapping (station_id → TAZID)            │\n",
    "│       │                                                             │\n",
    "│       ▼                                                             │\n",
    "│  Zone-Level Hourly Demand (sum of station volumes per zone)         │\n",
    "│       │                                                             │\n",
    "│       ▼                                                             │\n",
    "│  Feature Engineering                                                │\n",
    "│     hour, dayofweek, month, season, is_weekend, lag_1, lag_24      │\n",
    "│       │                                                             │\n",
    "│       ▼                                                             │\n",
    "│  Model Training (Linear Regression, Ridge)                          │\n",
    "│     Train: 80% | Test: 20% (time-ordered)                           │\n",
    "│       │                                                             │\n",
    "│       ▼                                                             │\n",
    "│  Evaluation: MAE, RMSE per zone                                     │\n",
    "│       │                                                             │\n",
    "│       ▼                                                             │\n",
    "│  Streamlit Dashboard (demand forecast + peak detection)             │\n",
    "└─────────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23c3d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib .pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "warnings .filterwarnings ('ignore')\n",
    "from sklearn .linear_model import LinearRegression ,Ridge\n",
    "from sklearn .metrics import mean_absolute_error ,mean_squared_error\n",
    "from sklearn .model_selection import train_test_split\n",
    "BASE_DIR =os .path .dirname (os .path .abspath ('__file__'))if '__file__'in dir ()else os .getcwd ()\n",
    "RAW_DIR =os .path .join (BASE_DIR ,'20220901-20230228_station-raw')\n",
    "CLEAN_DIR =os .path .join (BASE_DIR ,'processed')\n",
    "STATION_INFO_PATH =os .path .join (RAW_DIR ,'station_information.csv')\n",
    "RAW_5MIN_GLOB =os .path .join (RAW_DIR ,'charge_5min','*.csv')\n",
    "OUT_5MIN =os .path .join (CLEAN_DIR ,'charge_5min')\n",
    "OUT_1HOUR =os .path .join (CLEAN_DIR ,'charge_1hour')\n",
    "OUT_ZONE =os .path .join (CLEAN_DIR ,'zone_hourly_volume_long.csv')\n",
    "os .makedirs (OUT_5MIN ,exist_ok =True )\n",
    "os .makedirs (OUT_1HOUR ,exist_ok =True )\n",
    "print (' Directories ready')\n",
    "print (f'   RAW:     {RAW_DIR }')\n",
    "print (f'   OUTPUT:  {CLEAN_DIR }')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a84541",
   "metadata": {},
   "source": [
    "## 3. Station Information & Zone Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ccb690",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_info =pd .read_csv (STATION_INFO_PATH )\n",
    "print (f'Stations: {len (station_info )}')\n",
    "print (f'Zones covered: {station_info [\"TAZID\"].nunique ()}')\n",
    "station_info .head ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bdb721",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_info .describe ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7597eaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_to_zone =dict (zip (station_info ['station_id'],station_info ['TAZID']))\n",
    "print (f'Built mapping for {len (station_to_zone )} stations')\n",
    "fig ,ax =plt .subplots (1 ,2 ,figsize =(12 ,4 ))\n",
    "station_info ['slow_count'].hist (bins =20 ,ax =ax [0 ],color ='steelblue')\n",
    "ax [0 ].set_title ('Distribution of Slow Chargers per Station')\n",
    "ax [0 ].set_xlabel ('Slow Charger Count')\n",
    "station_info ['fast_count'].hist (bins =20 ,ax =ax [1 ],color ='darkorange')\n",
    "ax [1 ].set_title ('Distribution of Fast Chargers per Station')\n",
    "ax [1 ].set_xlabel ('Fast Charger Count')\n",
    "plt .tight_layout ()\n",
    "plt .show ()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4b6cc0",
   "metadata": {},
   "source": [
    "## 4. Raw Data Exploration (Single Station Sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c27d258",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_path =os .path .join (RAW_DIR ,'charge_5min','1001.csv')\n",
    "sample_df =pd .read_csv (sample_path )\n",
    "sample_df ['time']=pd .to_datetime (sample_df ['time'])\n",
    "print (f'Shape: {sample_df .shape }')\n",
    "print (f'Date range: {sample_df [\"time\"].min ()}  →  {sample_df [\"time\"].max ()}')\n",
    "print (f'Columns: {list (sample_df .columns )}')\n",
    "print (f'Nulls:\\n{sample_df .isnull ().sum ()}')\n",
    "sample_df .head ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6488741a",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_desc ={'time':'Timestamp (5-min intervals)','busy':'Number of piles currently charging','idle':'Number of piles available','s_price':'Service charge price (CNY/kWh)','e_price':'Electricity price (CNY/kWh)','fast_busy':'Fast charger piles in use','fast_idle':'Fast charger piles idle','slow_busy':'Slow charger piles in use','slow_idle':'Slow charger piles idle','duration':'Total charging duration in interval (hours)','volume':'Total energy dispensed in interval (kWh)',}\n",
    "pd .DataFrame .from_dict (col_desc ,orient ='index',columns =['Description'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc681e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig ,axes =plt .subplots (2 ,1 ,figsize =(14 ,7 ),sharex =False )\n",
    "sample_daily =sample_df .set_index ('time')['volume'].resample ('h').sum ()\n",
    "sample_daily .plot (ax =axes [0 ],color ='teal')\n",
    "axes [0 ].set_title ('Station 1001 — Hourly Energy Volume (kWh) Over Dataset Period')\n",
    "axes [0 ].set_ylabel ('kWh')\n",
    "sample_df ['hour']=sample_df ['time'].dt .hour\n",
    "hourly_avg =sample_df .groupby ('hour')['volume'].mean ()\n",
    "hourly_avg .plot (kind ='bar',ax =axes [1 ],color ='teal')\n",
    "axes [1 ].set_title ('Station 1001 — Average Energy Volume by Hour')\n",
    "axes [1 ].set_xlabel ('Hour of Day')\n",
    "axes [1 ].set_ylabel ('Avg kWh')\n",
    "plt .tight_layout ()\n",
    "plt .show ()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69412f55",
   "metadata": {},
   "source": [
    "## 5. Preprocessing — All Stations (5-min cleaning + gap fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fc3b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "BAD_STATIONS ={2129 ,1663 ,1478 ,1082 ,1055 ,1722 ,1039 ,1036 ,1681 ,2125 ,1487 ,1113 ,2138 ,1034 ,1337 ,1497 ,2337 ,1501 ,1101 ,2291 }\n",
    "EXPECTED_5MIN_FREQ ='5min'\n",
    "files =sorted (glob .glob (RAW_5MIN_GLOB ))\n",
    "print (f'Total raw station files: {len (files )}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3200fdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "success ,skipped ,fail =[],[],[]\n",
    "for file_path in files :\n",
    "    station_id =int (os .path .basename (file_path ).replace ('.csv',''))\n",
    "    if station_id in BAD_STATIONS :\n",
    "        skipped .append (station_id )\n",
    "        continue\n",
    "    if station_id not in station_to_zone :\n",
    "        skipped .append (station_id )\n",
    "        continue\n",
    "    zone_id =station_to_zone [station_id ]\n",
    "    try :\n",
    "        df =pd .read_csv (file_path )\n",
    "        if len (df )<10 :\n",
    "            skipped .append (station_id )\n",
    "            continue\n",
    "        df ['time']=pd .to_datetime (df ['time'])\n",
    "        df ['TAZID']=zone_id\n",
    "        df =df .sort_values ('time').set_index ('time')\n",
    "        full_index =pd .date_range (start =df .index .min (),end =df .index .max (),freq =EXPECTED_5MIN_FREQ )\n",
    "        df =df .reindex (full_index )\n",
    "        df =df .ffill ().bfill ()\n",
    "        df =df .reset_index ().rename (columns ={'index':'time'})\n",
    "        null_count =df .isnull ().sum ().sum ()\n",
    "        if null_count >0 :\n",
    "            fail .append (station_id )\n",
    "            continue\n",
    "        out_path =os .path .join (OUT_5MIN ,f'{station_id }.csv')\n",
    "        df .to_csv (out_path ,index =False )\n",
    "        success .append (station_id )\n",
    "    except Exception as e :\n",
    "        print (f'   Station {station_id }: {e }')\n",
    "        fail .append (station_id )\n",
    "print (f'\\n Cleaned: {len (success )} stations')\n",
    "print (f'⏭  Skipped (bad/unmapped): {len (skipped )} stations')\n",
    "print (f' Failed: {len (fail )} stations')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c18fd3f",
   "metadata": {},
   "source": [
    "## 6. Preprocessing — Hourly Aggregation (per-station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bde453f",
   "metadata": {},
   "outputs": [],
   "source": [
    "AGG_RULES ={'busy':'mean','idle':'mean','fast_busy':'mean','fast_idle':'mean','slow_busy':'mean','slow_idle':'mean','duration':'sum','volume':'sum','s_price':'mean','e_price':'mean','TAZID':'first',}\n",
    "cleaned_files =sorted (glob .glob (os .path .join (OUT_5MIN ,'*.csv')))\n",
    "print (f'Aggregating {len (cleaned_files )} stations to hourly …')\n",
    "for file_path in cleaned_files :\n",
    "    station_id =int (os .path .basename (file_path ).replace ('.csv',''))\n",
    "    df =pd .read_csv (file_path )\n",
    "    df ['time']=pd .to_datetime (df ['time'])\n",
    "    df =df .set_index ('time')\n",
    "    df_hourly =df .resample ('h').agg (AGG_RULES ).reset_index ()\n",
    "    out_path =os .path .join (OUT_1HOUR ,f'{station_id }.csv')\n",
    "    df_hourly .to_csv (out_path ,index =False )\n",
    "hourly_files =glob .glob (os .path .join (OUT_1HOUR ,'*.csv'))\n",
    "print (f' Hourly files written: {len (hourly_files )}')\n",
    "sample_h =pd .read_csv (hourly_files [0 ])\n",
    "print (f'   Sample shape: {sample_h .shape } — columns: {list (sample_h .columns )}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e014ffe",
   "metadata": {},
   "source": [
    "## 7. Zone-Level Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b6e63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data =[]\n",
    "for file_path in hourly_files :\n",
    "    df =pd .read_csv (file_path )\n",
    "    df ['time']=pd .to_datetime (df ['time'])\n",
    "    all_data .append (df [['time','TAZID','volume']])\n",
    "all_data =pd .concat (all_data ,ignore_index =True )\n",
    "zone_hourly =(all_data .groupby (['time','TAZID'],as_index =False ).agg ({'volume':'sum'}))\n",
    "zone_hourly .to_csv (OUT_ZONE ,index =False )\n",
    "print (f'Zone-hourly dataset: {zone_hourly .shape }')\n",
    "print (f'Zones: {zone_hourly [\"TAZID\"].nunique ()}')\n",
    "print (f'Time range: {zone_hourly [\"time\"].min ()} → {zone_hourly [\"time\"].max ()}')\n",
    "zone_hourly .head ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2e1d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Volume statistics (kWh) across all zones and hours:')\n",
    "zone_hourly ['volume'].describe ()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ee2288",
   "metadata": {},
   "source": [
    "## 8. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f9b3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_hourly_df =pd .read_csv (OUT_ZONE )\n",
    "zone_hourly_df ['time']=pd .to_datetime (zone_hourly_df ['time'])\n",
    "total_demand =zone_hourly_df .groupby ('time')['volume'].sum ()\n",
    "plt .figure (figsize =(16 ,4 ))\n",
    "total_demand .plot (color ='royalblue',linewidth =0.8 )\n",
    "plt .title ('Total EV Charging Demand (All Zones) — Hourly (kWh)')\n",
    "plt .ylabel ('kWh')\n",
    "plt .xlabel ('Time')\n",
    "plt .tight_layout ()\n",
    "plt .show ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba299f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_hourly_df ['hour']=zone_hourly_df ['time'].dt .hour\n",
    "zone_hourly_df ['dayofweek']=zone_hourly_df ['time'].dt .dayofweek\n",
    "zone_hourly_df ['month']=zone_hourly_df ['time'].dt .month\n",
    "fig ,axes =plt .subplots (1 ,3 ,figsize =(18 ,5 ))\n",
    "zone_hourly_df .groupby ('hour')['volume'].mean ().plot (kind ='bar',ax =axes [0 ],color ='steelblue')\n",
    "axes [0 ].set_title ('Avg Demand by Hour of Day')\n",
    "axes [0 ].set_xlabel ('Hour')\n",
    "axes [0 ].set_ylabel ('Avg kWh')\n",
    "days =['Mon','Tue','Wed','Thu','Fri','Sat','Sun']\n",
    "zone_hourly_df .groupby ('dayofweek')['volume'].mean ().plot (kind ='bar',ax =axes [1 ],color ='darkorange')\n",
    "axes [1 ].set_xticklabels (days ,rotation =0 )\n",
    "axes [1 ].set_title ('Avg Demand by Day of Week')\n",
    "axes [1 ].set_xlabel ('Day')\n",
    "zone_hourly_df .groupby ('month')['volume'].mean ().plot (kind ='bar',ax =axes [2 ],color ='seagreen')\n",
    "axes [2 ].set_title ('Avg Demand by Month')\n",
    "axes [2 ].set_xlabel ('Month')\n",
    "plt .tight_layout ()\n",
    "plt .show ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21867a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_zones =zone_hourly_df .groupby ('TAZID')['volume'].sum ().nlargest (10 )\n",
    "top_zones .plot (kind ='barh',figsize =(10 ,5 ),color ='mediumpurple')\n",
    "plt .title ('Top 10 Zones by Total Charging Demand (kWh)')\n",
    "plt .xlabel ('Total kWh')\n",
    "plt .tight_layout ()\n",
    "plt .show ()\n",
    "print (top_zones )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff131a53",
   "metadata": {},
   "source": [
    "## 9. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eb1096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features (df :pd .DataFrame )->pd .DataFrame :\n",
    "    \"\"\"Add time-based and lag features to a zone dataframe.\"\"\"\n",
    "    df =df .copy ()\n",
    "    df ['hour']=df .index .hour\n",
    "    df ['dayofweek']=df .index .dayofweek\n",
    "    df ['month']=df .index .month\n",
    "    df ['is_weekend']=(df .index .dayofweek >=5 ).astype (int )\n",
    "    df ['season']=df ['month'].map ({12 :0 ,1 :0 ,2 :0 ,3 :1 ,4 :1 ,5 :1 ,6 :2 ,7 :2 ,8 :2 ,9 :3 ,10 :3 ,11 :3 })\n",
    "    df ['hour_sin']=np .sin (2 *np .pi *df ['hour']/24 )\n",
    "    df ['hour_cos']=np .cos (2 *np .pi *df ['hour']/24 )\n",
    "    df ['dow_sin']=np .sin (2 *np .pi *df ['dayofweek']/7 )\n",
    "    df ['dow_cos']=np .cos (2 *np .pi *df ['dayofweek']/7 )\n",
    "    df ['lag_1h']=df ['volume'].shift (1 )\n",
    "    df ['lag_24h']=df ['volume'].shift (24 )\n",
    "    df ['lag_168h']=df ['volume'].shift (168 )\n",
    "    df ['roll_24h_mean']=df ['volume'].shift (1 ).rolling (24 ).mean ()\n",
    "    return df .dropna ()\n",
    "FEATURES =['hour','dayofweek','month','is_weekend','season','hour_sin','hour_cos','dow_sin','dow_cos','lag_1h','lag_24h','lag_168h','roll_24h_mean']\n",
    "print ('Feature set:')\n",
    "for f in FEATURES :\n",
    "    print (f'  · {f }')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9bd431",
   "metadata": {},
   "source": [
    "## 10. Model Training & Evaluation — All Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c6c429",
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_hourly_df =pd .read_csv (OUT_ZONE )\n",
    "zone_hourly_df ['time']=pd .to_datetime (zone_hourly_df ['time'])\n",
    "zones =zone_hourly_df ['TAZID'].unique ()\n",
    "results =[]\n",
    "for zone_id in zones :\n",
    "    zone_df =(zone_hourly_df [zone_hourly_df ['TAZID']==zone_id ].copy ().sort_values ('time').set_index ('time'))\n",
    "    zone_df =add_features (zone_df )\n",
    "    if len (zone_df )<200 :\n",
    "        continue\n",
    "    X =zone_df [FEATURES ]\n",
    "    y =zone_df ['volume']\n",
    "    X_train ,X_test ,y_train ,y_test =train_test_split (X ,y ,test_size =0.2 ,shuffle =False )\n",
    "    for name ,model in [('LinearRegression',LinearRegression ()),('Ridge',Ridge (alpha =1.0 ))]:\n",
    "        model .fit (X_train ,y_train )\n",
    "        y_pred =model .predict (X_test )\n",
    "        y_pred =np .maximum (y_pred ,0 )\n",
    "        mae =mean_absolute_error (y_test ,y_pred )\n",
    "        rmse =np .sqrt (mean_squared_error (y_test ,y_pred ))\n",
    "        results .append ({'zone':zone_id ,'model':name ,'MAE':mae ,'RMSE':rmse })\n",
    "results_df =pd .DataFrame (results )\n",
    "print (f'Evaluated {results_df [\"zone\"].nunique ()} zones')\n",
    "results_df .groupby ('model')[['MAE','RMSE']].mean ().round (3 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aebe376",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_per_zone =results_df .loc [results_df .groupby ('zone')['RMSE'].idxmin ()]\n",
    "print ('Model selection distribution (best RMSE per zone):')\n",
    "print (best_per_zone ['model'].value_counts ())\n",
    "fig ,axes =plt .subplots (1 ,2 ,figsize =(14 ,5 ))\n",
    "for name ,grp in results_df .groupby ('model'):\n",
    "    grp ['MAE'].hist (bins =30 ,ax =axes [0 ],alpha =0.6 ,label =name )\n",
    "    grp ['RMSE'].hist (bins =30 ,ax =axes [1 ],alpha =0.6 ,label =name )\n",
    "axes [0 ].set_title ('MAE Distribution — All Zones')\n",
    "axes [0 ].set_xlabel ('MAE (kWh)')\n",
    "axes [0 ].legend ()\n",
    "axes [1 ].set_title ('RMSE Distribution — All Zones')\n",
    "axes [1 ].set_xlabel ('RMSE (kWh)')\n",
    "axes [1 ].legend ()\n",
    "plt .tight_layout ()\n",
    "plt .show ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea19e341",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_save_path =os .path .join (CLEAN_DIR ,'zone_model_results.csv')\n",
    "results_df .to_csv (results_save_path ,index =False )\n",
    "print (f'Saved to: {results_save_path }')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d7f498",
   "metadata": {},
   "source": [
    "## 11. Detailed Zone Analysis — Single Zone Deep Dive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e82e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "busiest_zone =int (zone_hourly_df .groupby ('TAZID')['volume'].sum ().idxmax ())\n",
    "print (f'Analysing busiest zone: {busiest_zone }')\n",
    "zdf =(zone_hourly_df [zone_hourly_df ['TAZID']==busiest_zone ].copy ().sort_values ('time').set_index ('time'))\n",
    "zdf =add_features (zdf )\n",
    "X =zdf [FEATURES ]\n",
    "y =zdf ['volume']\n",
    "X_train ,X_test ,y_train ,y_test =train_test_split (X ,y ,test_size =0.2 ,shuffle =False )\n",
    "model =Ridge (alpha =1.0 )\n",
    "model .fit (X_train ,y_train )\n",
    "y_pred =np .maximum (model .predict (X_test ),0 )\n",
    "mae =mean_absolute_error (y_test ,y_pred )\n",
    "rmse =np .sqrt (mean_squared_error (y_test ,y_pred ))\n",
    "print (f'Zone {busiest_zone }  →  MAE: {mae :.2f} kWh | RMSE: {rmse :.2f} kWh')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706ca68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig ,ax =plt .subplots (figsize =(14 ,5 ))\n",
    "ax .plot (y_test .index ,y_test .values ,label ='Actual',linewidth =1.5 ,color ='royalblue')\n",
    "ax .plot (y_test .index ,y_pred ,label ='Predicted (Ridge)',linestyle ='--',linewidth =1.2 ,color ='tomato')\n",
    "ax .set_title (f'Zone {busiest_zone } — Actual vs Predicted Charging Demand (Test Set)')\n",
    "ax .set_xlabel ('Time')\n",
    "ax .set_ylabel ('Energy Demand (kWh)')\n",
    "ax .legend ()\n",
    "ax .grid (True ,alpha =0.3 )\n",
    "plt .tight_layout ()\n",
    "plt .show ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97336b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_hours =zdf ['volume'].nlargest (10 )\n",
    "print (f'Top 10 Peak Demand Hours — Zone {busiest_zone }:')\n",
    "print (peak_hours .to_string ())\n",
    "zdf ['hour']=zdf .index .hour\n",
    "zdf ['dayofweek']=zdf .index .dayofweek\n",
    "pivot =zdf .pivot_table (values ='volume',index ='hour',columns ='dayofweek',aggfunc ='mean')\n",
    "pivot .columns =['Mon','Tue','Wed','Thu','Fri','Sat','Sun']\n",
    "plt .figure (figsize =(10 ,7 ))\n",
    "sns .heatmap (pivot ,cmap ='YlOrRd',linewidths =0.5 ,annot =False )\n",
    "plt .title (f'Zone {busiest_zone } — Avg kWh by Hour × Day of Week')\n",
    "plt .ylabel ('Hour of Day')\n",
    "plt .xlabel ('Day')\n",
    "plt .tight_layout ()\n",
    "plt .show ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48ed70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df =pd .DataFrame ({'feature':FEATURES ,'coefficient':model .coef_ })\n",
    "coef_df =coef_df .sort_values ('coefficient',key =abs ,ascending =True )\n",
    "coef_df .plot (kind ='barh',x ='feature',y ='coefficient',figsize =(10 ,6 ),color =['crimson'if v <0 else 'steelblue'for v in coef_df ['coefficient']])\n",
    "plt .title (f'Ridge Regression Coefficients — Zone {busiest_zone }')\n",
    "plt .xlabel ('Coefficient Value')\n",
    "plt .axvline (x =0 ,color ='black',linewidth =0.8 )\n",
    "plt .tight_layout ()\n",
    "plt .show ()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c63de9",
   "metadata": {},
   "source": [
    "## 12. Summary — Milestone 1 Evaluation\n",
    "\n",
    "### What was built\n",
    "| Step | Description |\n",
    "|---|---|\n",
    "| Preprocessing | Gap-filled 5-min station CSVs using ffill/bfill; removed 20 bad stations |\n",
    "| Aggregation | Resampled to 1-hour intervals; summed per zone |\n",
    "| Feature Engineering | Time features + sin/cos encoding + 3 lag features + rolling mean |\n",
    "| Models | Linear Regression, Ridge Regression (per zone) |\n",
    "| Evaluation | MAE and RMSE on chronological 20% test split |\n",
    "\n",
    "### Key Findings\n",
    "- Demand peaks in the **evening (18:00–21:00)** and is lowest **01:00–05:00**\n",
    "- **Weekday** demand generally exceeds weekend demand\n",
    "- **lag_1h** and **lag_24h** are the strongest predictors\n",
    "- Ridge Regression outperforms plain Linear Regression on high-demand zones\n",
    "\n",
    "### Next Steps (Milestone 2)\n",
    "- LSTM / GRU time-series models for non-linear capture\n",
    "- Add weather data as exogenous feature\n",
    "- Spatial graph neural networks using `adj.csv`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}